{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRAEl1ZTRDAP"
      },
      "source": [
        "Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z87z_4jUQuwV",
        "outputId": "54cee8d0-5517-400b-feca-7bd349831e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1: treacle, lory, dodo, tell, haven, right, cat, duchess, caterpillar, said\n",
            "Topic 2: glad, certainly, spoke, tone, began, cried, ve, replied, looked, alice\n",
            "Topic 3: story, soup, deep, sigh, different, replied, cried, course, mock, turtle\n",
            "Topic 4: things, didn, true, history, come, means, ask, thing, mad, know\n",
            "Topic 5: pattering, golden, heard, oh, rabbit, poor, came, thing, door, little\n",
            "Topic 6: try, cats, people, candle, cat, sky, telescope, look, thing, like\n",
            "Topic 7: day, dear, heads, croquet, come, shrill, hearts, shouted, voice, queen\n",
            "Topic 8: interrupted, wish, just, place, took, mad, looked, tea, march, hare\n",
            "Topic 9: pepper, shall, speaking, long, game, right, use, poor, come, thought\n",
            "Topic 10: saw, felt, long, life, caterpillar, round, away, quite, just, time\n",
            "Topic 11: right, dear, good, say, just, curious, moment, got, better, think\n",
            "Topic 12: curious, called, lessons, added, reason, cried, shoes, lobsters, replied, gryphon\n",
            "Topic 13: knocking, tell, tears, perfectly, manage, turning, moment, door, table, went\n",
            "Topic 14: natural, proper, frightened, quite, shall, tell, come, trying, mouse, way\n",
            "Topic 15: heard, look, live, dare, asked, dormouse, quite, began, say, did\n",
            "Topic 16: tea, added, asleep, replied, tone, just, ve, thing, dormouse, hatter\n",
            "Topic 17: called, funny, dinah, cat, eat, oh, dear, come, tell, ll\n",
            "Topic 18: going, shook, came, voice, looking, got, great, minute, began, head\n",
            "Topic 19: care, mean, tone, words, caterpillar, oh, want, duchess, look, don\n",
            "Topic 20: anxiously, look, evidence, witness, looked, read, jury, white, rabbit, king\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import numpy as np\n",
        "\n",
        "#  dataset\n",
        "file_path = 'alice.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "# Preprocessing and vectorization\n",
        "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = vectorizer.fit_transform(text_data.split(\"\\n\"))  \n",
        "\n",
        "# Applying NMF\n",
        "n_topics = 20\n",
        "nmf_model = NMF(n_components=n_topics, random_state=1)\n",
        "W = nmf_model.fit_transform(tfidf)\n",
        "H = nmf_model.components_\n",
        "\n",
        "# Getting the vocabulary\n",
        "words = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the top words for each topic\n",
        "for i, topic in enumerate(H):\n",
        "    top_words_index = topic.argsort()[-10:]\n",
        "    print(f\"Topic {i + 1}: {', '.join(words[top_words_index])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80SZ0u3WQ1lD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
